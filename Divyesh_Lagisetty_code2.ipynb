{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e60aee23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import linear regression, decision tree regressor and ada boost regressor, random forest regressor, xgboost regressor, ridge regressor, lasso regressor, elastic net regressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# run grid search on the above regressors, and use k fold cross validation\n",
    "# make sure the number of canidates for each hyperparameter is less than 4\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "# import mean squared error and r2 score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# import joblib to save the model\n",
    "import joblib\n",
    "\n",
    "# ignore all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f942bcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_data = np.load('ptrain_pca.npy')\n",
    "test_data = np.load('ptest_pca.npy')\n",
    "targets = pd.read_csv('training_data_targets.csv', header=None).to_numpy()[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c18a5e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.175019 using {'fit_intercept': False}\n"
     ]
    }
   ],
   "source": [
    "# start with linear regression\n",
    "# define the model\n",
    "model = LinearRegression()\n",
    "# define the grid search\n",
    "grid = dict()\n",
    "grid['fit_intercept'] = [True, False]\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=10, scoring='r2')\n",
    "# perform the search\n",
    "grid_result = grid_search.fit(train_data, targets)\n",
    "# summarize the results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# save best parameters as a dictionary\n",
    "best_params = grid_result.best_params_\n",
    "# save as a json file\n",
    "import json\n",
    "with open('linear_regression_best_params_pca.json', 'w') as f:\n",
    "    json.dump(best_params, f)\n",
    "# save the model\n",
    "joblib.dump(grid_result.best_estimator_, 'linear_regression_pca.pkl')\n",
    "# evaluate the model\n",
    "y_pred = grid_result.predict(test_data)\n",
    "#save results\n",
    "np.save('linear_regression_results_pca.npy', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6bf263a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -198761.567201 using {'alpha': 10, 'max_iter': 2000, 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "# ridge regression\n",
    "# define the model\n",
    "model = Ridge()\n",
    "# define the grid search\n",
    "grid = dict()\n",
    "grid['alpha'] = [0.1, 1, 10]\n",
    "grid['max_iter'] = [1000, 2000, 4000]\n",
    "grid['solver'] = ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=10, scoring='neg_mean_squared_error')\n",
    "# perform the search\n",
    "grid_result = grid_search.fit(train_data, targets)\n",
    "# summarize the results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "best_params = grid_result.best_params_\n",
    "# save as a json file\n",
    "with open('ridge_regression_best_params_pca.json', 'w') as f:\n",
    "    json.dump(best_params, f)\n",
    "# save the model\n",
    "joblib.dump(grid_result.best_estimator_, 'ridge_regression_pca.pkl')\n",
    "# evaluate the model\n",
    "y_pred = grid_result.predict(test_data)\n",
    "#save results\n",
    "np.save('ridge_regression_results_pca.npy', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cc4c3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.482418 using {'alpha': 10, 'max_iter': 4000, 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "# ridge regression\n",
    "# define the model\n",
    "model = Ridge()\n",
    "# define the grid search\n",
    "grid = dict()\n",
    "grid['alpha'] = [0.1, 1, 10]\n",
    "grid['max_iter'] = [1000, 2000, 4000]\n",
    "grid['solver'] = ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=10, scoring='r2')\n",
    "# perform the search\n",
    "grid_result = grid_search.fit(train_data, targets)\n",
    "# summarize the results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "best_params = grid_result.best_params_\n",
    "# save as a json file\n",
    "with open('ridge_regression_best_params_pca.json', 'w') as f:\n",
    "    json.dump(best_params, f)\n",
    "# save the model\n",
    "joblib.dump(grid_result.best_estimator_, 'ridge_regression_pca.pkl')\n",
    "# evaluate the model\n",
    "y_pred = grid_result.predict(test_data)\n",
    "#save results\n",
    "np.save('ridge_regression_results_pca.npy', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3050c860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.890967 using {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 8}\n"
     ]
    }
   ],
   "source": [
    "# decision tree regressor\n",
    "# define the model\n",
    "model = DecisionTreeRegressor()\n",
    "# define the grid search\n",
    "grid = dict()\n",
    "grid['max_depth'] = [None, 10, 100, 500]\n",
    "grid['min_samples_split'] = [2, 4, 8]\n",
    "grid['min_samples_leaf'] = [1, 2, 4]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=10, scoring='r2')\n",
    "# perform the search\n",
    "\n",
    "grid_result = grid_search.fit(train_data, targets)\n",
    "# summarize the results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "best_params = grid_result.best_params_\n",
    "# save as a json file\n",
    "with open('decision_tree_regressor_best_params_pca.json', 'w') as f:\n",
    "    json.dump(best_params, f)\n",
    "# save the model\n",
    "joblib.dump(grid_result.best_estimator_, 'decision_tree_regressor_pca.pkl')\n",
    "# evaluate the model\n",
    "y_pred = grid_result.predict(test_data)\n",
    "#save results\n",
    "np.save('decision_tree_regressor_results_pca.npy', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8478a472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -52053.822410 using {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 8}\n"
     ]
    }
   ],
   "source": [
    "# decision tree regressor\n",
    "# define the model\n",
    "model = DecisionTreeRegressor()\n",
    "# define the grid search\n",
    "grid = dict()\n",
    "grid['max_depth'] = [None, 10, 100, 500]\n",
    "grid['min_samples_split'] = [2, 4, 8]\n",
    "grid['min_samples_leaf'] = [1, 2, 4]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=10, scoring='neg_mean_squared_error')\n",
    "# perform the search\n",
    "\n",
    "grid_result = grid_search.fit(train_data, targets)\n",
    "# summarize the results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "best_params = grid_result.best_params_\n",
    "# save as a json file\n",
    "with open('decision_tree_regressor_best_params_pca.json', 'w') as f:\n",
    "    json.dump(best_params, f)\n",
    "# save the model\n",
    "joblib.dump(grid_result.best_estimator_, 'decision_tree_regressor_pca.pkl')\n",
    "# evaluate the model\n",
    "y_pred = grid_result.predict(test_data)\n",
    "#save results\n",
    "np.save('decision_tree_regressor_results_pca.npy', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae149ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.851712 using {'learning_rate': 0.001, 'loss': 'linear', 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# ada boost regressor\n",
    "# define the model\n",
    "model = AdaBoostRegressor()\n",
    "# define the grid search\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [10, 100, 1000]\n",
    "grid['learning_rate'] = [0.001, 0.01, 0.1, 1.0]\n",
    "grid['loss'] = ['linear', 'square', 'exponential']\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=5, scoring='r2')\n",
    "# perform the search\n",
    "\n",
    "grid_result = grid_search.fit(train_data, targets)\n",
    "# summarize the results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "best_params = grid_result.best_params_\n",
    "# save as a json file\n",
    "with open('ada_boost_regressor_best_params.json_pca', 'w') as f:\n",
    "    json.dump(best_params, f)\n",
    "# save the model\n",
    "joblib.dump(grid_result.best_estimator_, 'ada_boost_regressor_pca.pkl')\n",
    "# evaluate the model\n",
    "y_pred = grid_result.predict(test_data)\n",
    "#save results\n",
    "np.save('ada_boost_regressor_results_pca.npy', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a302d88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.890539 using {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# random forest regressor\n",
    "# define the model\n",
    "model = RandomForestRegressor()\n",
    "# define the grid search\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [10, 100, 200]\n",
    "grid['max_depth'] = [None, 10, 60, 100]\n",
    "grid['min_samples_split'] = [2, 4, 8]\n",
    "grid['min_samples_leaf'] = [1, 2, 4]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=10, scoring='r2')\n",
    "# perform the search\n",
    "\n",
    "grid_result = grid_search.fit(train_data, targets)\n",
    "# summarize the results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "best_params = grid_result.best_params_\n",
    "# save as a json file\n",
    "with open('random_forest_regressor_best_params_pca.json', 'w') as f:\n",
    "    json.dump(best_params, f)\n",
    "# save the model\n",
    "joblib.dump(grid_result.best_estimator_, 'random_forest_regressor_pca.pkl')\n",
    "# evaluate the model\n",
    "y_pred = grid_result.predict(test_data)\n",
    "#save results\n",
    "np.save('random_forest_regressor_results_pca.npy', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1d11bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = XGBRegressor()\n",
    "# define the grid search\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [10, 100, 500, 1000]\n",
    "grid['max_depth'] = [5, 10, 100]\n",
    "grid['learning_rate'] = [0.001, 0.01, 0.1, 1.0]\n",
    "grid['booster'] = ['gbtree', 'gblinear', 'dart']\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=10, scoring='r2')\n",
    "# perform the search\n",
    "\n",
    "grid_result = grid_search.fit(train_data, targets)\n",
    "# summarize the results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "best_params = grid_result.best_params_\n",
    "# save as a json file\n",
    "import json\n",
    "with open('xgboost_regression_best_params.json_pca', 'w') as f:\n",
    "    json.dump(best_params, f)\n",
    "# save the model\n",
    "joblib.dump(grid_result.best_estimator_, 'xgboost_regressor_pca.pkl')\n",
    "# evaluate the model\n",
    "y_pred = grid_result.predict(test_data)\n",
    "#save results\n",
    "np.save('xgboost_regressor_results.npy_pca', y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81201ffe",
   "metadata": {},
   "source": [
    "## Using Negative Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02c03a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.log(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbbf7ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -17.599714 using {'fit_intercept': False}\n"
     ]
    }
   ],
   "source": [
    "# start with linear regression\n",
    "# define the model\n",
    "model = LinearRegression()\n",
    "# define the grid search\n",
    "grid = dict()\n",
    "grid['fit_intercept'] = [True, False]\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=10, scoring='neg_mean_squared_error')\n",
    "# perform the search\n",
    "grid_result = grid_search.fit(train_data, targets)\n",
    "# summarize the results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# save best parameters as a dictionary\n",
    "best_params = grid_result.best_params_\n",
    "# save as a json file\n",
    "import json\n",
    "with open('linear_regression_best_params_pca_nmse.json', 'w') as f:\n",
    "    json.dump(best_params, f)\n",
    "# save the model\n",
    "joblib.dump(grid_result.best_estimator_, 'linear_regression_pca_nmse.pkl')\n",
    "# evaluate the model\n",
    "y_pred = grid_result.predict(test_data)\n",
    "#save results\n",
    "np.save('linear_regression_results_pca_nmse.npy', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9eea3a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -3.491327 using {'alpha': 10, 'max_iter': 2000, 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "# ridge regression\n",
    "# define the model\n",
    "model = Ridge()\n",
    "# define the grid search\n",
    "grid = dict()\n",
    "grid['alpha'] = [0.1, 1, 10]\n",
    "grid['max_iter'] = [1000, 2000, 4000]\n",
    "grid['solver'] = ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=10, scoring='neg_mean_squared_error')\n",
    "# perform the search\n",
    "grid_result = grid_search.fit(train_data, targets)\n",
    "# summarize the results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "best_params = grid_result.best_params_\n",
    "# save as a json file\n",
    "with open('ridge_regression_best_params_pca_nmse.json', 'w') as f:\n",
    "    json.dump(best_params, f)\n",
    "# save the model\n",
    "joblib.dump(grid_result.best_estimator_, 'ridge_regression_pca_nmse.pkl')\n",
    "# evaluate the model\n",
    "y_pred = grid_result.predict(test_data)\n",
    "#save results\n",
    "np.save('ridge_regression_results_pca.npy_nmse', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bd4756b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.164042 using {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 8}\n"
     ]
    }
   ],
   "source": [
    "# decision tree regressor\n",
    "# define the model\n",
    "model = DecisionTreeRegressor()\n",
    "# define the grid search\n",
    "grid = dict()\n",
    "grid['max_depth'] = [None, 10, 100, 500]\n",
    "grid['min_samples_split'] = [2, 4, 8]\n",
    "grid['min_samples_leaf'] = [1, 2, 4]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=10, scoring='neg_mean_squared_error')\n",
    "# perform the search\n",
    "\n",
    "grid_result = grid_search.fit(train_data, targets)\n",
    "# summarize the results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "best_params = grid_result.best_params_\n",
    "# save as a json file\n",
    "with open('decision_tree_regressor_best_params_pca_nmse.json', 'w') as f:\n",
    "    json.dump(best_params, f)\n",
    "# save the model\n",
    "joblib.dump(grid_result.best_estimator_, 'decision_tree_regressor_pca_nmse.pkl')\n",
    "# evaluate the model\n",
    "y_pred = grid_result.predict(test_data)\n",
    "#save results\n",
    "np.save('decision_tree_regressor_results_pca_nmse.npy', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7532b603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.335058 using {'learning_rate': 0.01, 'loss': 'linear', 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# ada boost regressor\n",
    "# define the model\n",
    "model = AdaBoostRegressor()\n",
    "# define the grid search\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [10, 100, 1000]\n",
    "grid['learning_rate'] = [0.001, 0.01, 0.1, 1.0]\n",
    "grid['loss'] = ['linear', 'square', 'exponential']\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=5, scoring='neg_mean_squared_error')\n",
    "# perform the search\n",
    "\n",
    "grid_result = grid_search.fit(train_data, targets)\n",
    "# summarize the results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "best_params = grid_result.best_params_\n",
    "# save as a json file\n",
    "with open('ada_boost_regressor_best_params.json_pca_nmse', 'w') as f:\n",
    "    json.dump(best_params, f)\n",
    "# save the model\n",
    "joblib.dump(grid_result.best_estimator_, 'ada_boost_regressor_pca_nmse.pkl')\n",
    "# evaluate the model\n",
    "y_pred = grid_result.predict(test_data)\n",
    "#save results\n",
    "np.save('ada_boost_regressor_results_pca_nmse.npy', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "687907cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.136311 using {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# random forest regressor\n",
    "# define the model\n",
    "model = RandomForestRegressor()\n",
    "# define the grid search\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [10, 100, 200]\n",
    "grid['max_depth'] = [10, 60, 100, 500]\n",
    "grid['min_samples_split'] = [2, 4, 8]\n",
    "grid['min_samples_leaf'] = [1, 2, 4]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=10, scoring='neg_mean_squared_error')\n",
    "# perform the search\n",
    "\n",
    "grid_result = grid_search.fit(train_data, targets)\n",
    "# summarize the results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "best_params = grid_result.best_params_\n",
    "# save as a json file\n",
    "with open('random_forest_regressor_best_params_pca_nmse.json', 'w') as f:\n",
    "    json.dump(best_params, f)\n",
    "# save the model\n",
    "joblib.dump(grid_result.best_estimator_, 'random_forest_regressor_pca_nmse.pkl')\n",
    "# evaluate the model\n",
    "y_pred = grid_result.predict(test_data)\n",
    "#save results\n",
    "np.save('random_forest_regressor_results_pca_nmse.npy', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22d56c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.110677 using {'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = XGBRegressor()\n",
    "# define the grid search\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [10, 100, 500, 1000]\n",
    "grid['max_depth'] = [5, 10, 100]\n",
    "grid['learning_rate'] = [0.001, 0.01, 0.1, 1.0]\n",
    "grid['booster'] = ['gbtree', 'gblinear', 'dart']\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=10, scoring='neg_mean_squared_error')\n",
    "# perform the search\n",
    "\n",
    "grid_result = grid_search.fit(train_data, targets)\n",
    "# summarize the results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "best_params = grid_result.best_params_\n",
    "# save as a json file\n",
    "import json\n",
    "with open('xgboost_regression_best_params.json_pca_nmse', 'w') as f:\n",
    "    json.dump(best_params, f)\n",
    "# save the model\n",
    "joblib.dump(grid_result.best_estimator_, 'xgboost_regressor_pca_nmse.pkl')\n",
    "# evaluate the model\n",
    "y_pred = grid_result.predict(test_data)\n",
    "#save results\n",
    "np.save('xgboost_regressor_results.npy_pca_nmse', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d096b64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
